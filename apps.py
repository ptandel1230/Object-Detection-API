# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o1nez-wT4nFtGSNrzMA0FLBeJTcXfLNz
"""

from flask import Flask, request, jsonify
import torch
import torchvision.transforms as T
from PIL import Image
import io
import torchvision.models.detection as detection
import os

app = Flask(__name__)

# Load the saved model
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model = detection.fasterrcnn_resnet50_fpn(pretrained=False)
model.load_state_dict(torch.load('fasterrcnn_model.pkl'))  # Change path if necessary
model.to(device)
model.eval()

# Define the COCO labels
COCO_LABELS = [
    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',
    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',
    'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',
    'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop', 'mouse',
    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',
    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'Tree'
]

def transform_image(image_bytes):
    transform = T.Compose([T.ToTensor()])
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    return transform(image).unsqueeze(0)

@app.route('/predict', methods=['POST'])
def predict():
    if 'file' not in request.files:
        return jsonify({"error": "No file provided"}), 400

    file = request.files['file']
    image_bytes = file.read()
    img = transform_image(image_bytes).to(device)

    with torch.no_grad():
        prediction = model(img)[0]

    # Extract boxes, labels, and scores
    boxes = prediction['boxes'].cpu().numpy().tolist()
    labels = prediction['labels'].cpu().numpy().tolist()
    scores = prediction['scores'].cpu().numpy().tolist()

    results = []
    for box, label, score in zip(boxes, labels, scores):
        if score > 0.5:  # filter by confidence score
            results.append({
                'label': COCO_LABELS[label],
                'score': score,
                'box': box
            })

    return jsonify(results)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)



